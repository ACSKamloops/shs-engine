"""
Helper script to submit a Pukaist batch JSONL file to an OpenAI-compatible
Batch API endpoint.

This script is intentionally minimal and local-first:
- It reads a JSONL file generated by `python -m src.batch_llm prepare`.
- It posts that file as the input for a batch job using the configured
  base URL and API key.
- It prints the batch identifier so you can monitor and fetch results using
  the provider's own CLI or HTTP tools.

NOTE: The exact Batch API shape can vary by provider/version. This helper
assumes a simple POST to `{base_url}/v1/batch` with the JSONL file as the
request body and `Content-Type: application/jsonl`. Adjust or wrap as
needed to match the latest GPT‑5‑nano Batch docs you are using.
"""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

import os
import requests

from src.config import Settings


def submit_batch(jsonl_path: Path) -> str:
    settings = Settings.load()
    if not settings.llm_api_key or not settings.llm_base_url:
        raise SystemExit("LLM base URL and API key must be configured (PUKAIST_LLM_BASE_URL, PUKAIST_LLM_API_KEY).")

    if not jsonl_path.is_file():
        raise SystemExit(f"JSONL file not found: {jsonl_path}")

    url = settings.llm_base_url.rstrip("/") + "/v1/batch"
    with jsonl_path.open("rb") as fh:
        data = fh.read()

    headers = {
        "Authorization": f"Bearer {settings.llm_api_key}",
        "Content-Type": "application/jsonl",
    }
    timeout = float(os.getenv("PUKAIST_BATCH_HTTP_TIMEOUT_SEC", "30.0"))
    resp = requests.post(url, headers=headers, data=data, timeout=timeout)
    try:
        resp.raise_for_status()
    except Exception as exc:  # noqa: BLE001
        sys.stderr.write(f"Batch submission failed: {exc}\n{resp.text}\n")
        raise

    payload = resp.json()
    batch_id = payload.get("id") or payload.get("batch_id") or "<unknown>"
    print(f"Submitted batch: {batch_id}")
    return str(batch_id)


def main() -> None:
    parser = argparse.ArgumentParser(description="Submit Pukaist batch JSONL to OpenAI-compatible Batch API.")
    parser.add_argument("file", help="Path to JSONL file produced by src.batch_llm.prepare")
    args = parser.parse_args()
    submit_batch(Path(args.file))


if __name__ == "__main__":
    main()
